{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install --quiet torch torchvision albumentations tqdm codecarbon optuna torchmetrics torchmetrics[detection]",
   "id": "7bfb6304a33dff58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T10:17:52.292908Z",
     "start_time": "2025-08-20T10:17:49.063053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import albumentations.pytorch\n",
    "import datasets as ds\n",
    "import utils\n",
    "import torch as t\n",
    "import torchvision as tv\n",
    "import albumentations as A\n",
    "from tqdm.auto import tqdm\n",
    "import torchmetrics as tm\n",
    "import optuna\n",
    "from codecarbon import EmissionsTracker\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "def sample_trial_config():\n",
    "    config = {\n",
    "        \"enable_horizontal_flip\": random.choice([True, False]),\n",
    "        \"enable_color_jitter\": random.choice([True, False]),\n",
    "        \"enable_affine\": random.choice([True, False])\n",
    "    }\n",
    "\n",
    "    # Only sample color_jitter params if enabled\n",
    "    if config[\"enable_color_jitter\"]:\n",
    "        config.update({\n",
    "            \"color_jitter_brightness\": random.choice([0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "            \"color_jitter_contrast\": random.choice([0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "            \"color_jitter_saturation\": random.choice([0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "            \"color_jitter_hue\": random.choice([0.1, 0.15, 0.2])\n",
    "        })\n",
    "\n",
    "    # Only sample affine params if enabled\n",
    "    if config[\"enable_affine\"]:\n",
    "        config[\"enable_affine_scale\"] = random.choice([True, False])\n",
    "        config[\"enable_affine_rotate\"] = random.choice([True, False])\n",
    "        config[\"enable_affine_shear\"] = random.choice([True, False])\n",
    "\n",
    "        if config.get(\"enable_affine_scale\", False):\n",
    "            scale_min = random.choice([0.05, 0.1, 0.15, 0.2])\n",
    "            scale_max = random.choice([0.2, 0.3, 0.4, 0.5])\n",
    "            config[\"affine_scale_min\"], config[\"affine_scale_max\"] = min(scale_min, scale_max), max(scale_min,\n",
    "                                                                                                    scale_max)\n",
    "\n",
    "        if config.get(\"enable_affine_rotate\", False):\n",
    "            rotate_min = random.choice([-20, -18, -15])\n",
    "            rotate_max = random.choice([15, 18, 20])\n",
    "            config[\"affine_rotate_min\"], config[\"affine_rotate_max\"] = min(rotate_min, rotate_max), max(rotate_min,\n",
    "                                                                                                        rotate_max)\n",
    "\n",
    "        if config.get(\"enable_affine_shear\", False):\n",
    "            shear_min = random.choice([-20, -18, -15])\n",
    "            shear_max = random.choice([15, 18, 20])\n",
    "            config[\"affine_shear_min\"], config[\"affine_shear_max\"] = min(shear_min, shear_max), max(shear_min,\n",
    "                                                                                                    shear_max)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def train_model(config: dict, num_epochs=3):\n",
    "    # for train\n",
    "    x2, y2 = ds.extract_all('./datasets/30/annotations.xml')\n",
    "    x3, y3 = ds.extract_all('./datasets/60/annotations.xml')\n",
    "    x4, y4 = ds.extract_all('./datasets/90/annotations.xml')\n",
    "    x6, y6 = ds.extract_all('./datasets/clear2/annotations.xml')\n",
    "    x7, y7 = ds.extract_all('./datasets/clear3/annotations.xml')\n",
    "    # for val\n",
    "    x0, y0 = ds.extract_all('./datasets/090/annotations.xml')\n",
    "    x1, y1 = ds.extract_all('./datasets/190/annotations.xml')\n",
    "    x5, y5 = ds.extract_all('./datasets/clear1/annotations.xml')\n",
    "\n",
    "    augmentations = []\n",
    "\n",
    "    if config.get(\"enable_horizontal_flip\", False):\n",
    "        augmentations.append(A.HorizontalFlip(p=0.5))\n",
    "    if config.get(\"enable_color_jitter\", False):\n",
    "        augmentations.append(A.ColorJitter(\n",
    "            brightness=config[\"color_jitter_brightness\"],\n",
    "            contrast=config[\"color_jitter_contrast\"],\n",
    "            saturation=config[\"color_jitter_saturation\"],\n",
    "            hue=config[\"color_jitter_hue\"]\n",
    "        ))\n",
    "    if config.get(\"enable_affine\", False):\n",
    "        kwords = {}\n",
    "        if config.get(\"enable_affine_scale\", False):\n",
    "            kwords[\"scale\"] = (config[\"affine_scale_min\"], config[\"affine_scale_max\"])\n",
    "        if config.get(\"enable_affine_rotate\", False):\n",
    "            kwords[\"rotate\"] = (config[\"affine_rotate_min\"], config[\"affine_rotate_max\"])\n",
    "        if config.get(\"enable_affine_shear\", False):\n",
    "            kwords[\"shear\"] = (config[\"affine_shear_min\"], config[\"affine_shear_max\"])\n",
    "        augmentations.append(A.Affine(**kwords, p=0.5))\n",
    "\n",
    "    train_ds = ds.CustomImageDataset([*x2, *x3, *x4, *x6, *x7], [*y2, *y3, *y4, *y6, *y7],\n",
    "                                     transform=A.Compose([*augmentations, albumentations.pytorch.ToTensorV2()],\n",
    "                                                         bbox_params=ds.albumentations_params))\n",
    "    val_ds = ds.CustomImageDataset([*x0, *x1, *x5], [*y0, *y1, *y5])\n",
    "\n",
    "    dl_train = t.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=utils.unroller)\n",
    "    dl_val = t.utils.data.DataLoader(val_ds, batch_size=4, shuffle=True, collate_fn=utils.unroller)\n",
    "\n",
    "    device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "\n",
    "    model = tv.models.detection.fasterrcnn_resnet50_fpn(weights='COCO_V1', backbone_weights='IMAGENET1K_V2').to(device)\n",
    "    model.roi_heads.box_predictor = tv.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "        in_channels=model.roi_heads.box_predictor.cls_score.in_features,\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = t.optim.SGD([p for p in model.parameters() if p.requires_grad],\n",
    "                            lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    metric = tm.detection.mean_ap.MeanAveragePrecision(box_format=\"xyxy\", iou_thresholds=[0.5])\n",
    "    val_map = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, targets in tqdm(dl_train, desc=f\"Train Epoch {epoch + 1}\", leave=True):\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "            total_loss = sum(loss for loss in loss_dict.values())\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += total_loss.item()\n",
    "        train_loss /= len(dl_train)\n",
    "\n",
    "        # ---- VALIDATION ----\n",
    "        val_loss = 0\n",
    "        metric.reset()\n",
    "        with t.no_grad():\n",
    "            for images, targets in dl_val:\n",
    "                images = [img.to(device) for img in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                # loss\n",
    "                model.train()\n",
    "                loss_dict = model(images, targets)\n",
    "                val_loss += sum(loss for loss in loss_dict.values())\n",
    "                # predictions\n",
    "                model.eval()\n",
    "                pred = model(images)\n",
    "                metric.update(pred, targets)\n",
    "        val_loss /= len(dl_val)\n",
    "        val_metrics = metric.compute()\n",
    "        val_map = val_metrics[\"map\"].item()\n",
    "        print(f\"epoch={epoch + 1}; train_loss={train_loss:.4f}; val_loss={val_loss:.4f}; val_map={val_map:.4f}\")\n",
    "\n",
    "    return val_map\n",
    "\n",
    "\n",
    "# optuna objective\n",
    "def objective(trial):\n",
    "    config = {}\n",
    "\n",
    "    config[\"enable_horizontal_flip\"] = trial.suggest_categorical(\"enable_horizontal_flip\", [True, False])\n",
    "\n",
    "    config[\"enable_color_jitter\"] = trial.suggest_categorical(\"enable_color_jitter\", [True, False])\n",
    "    if config[\"enable_color_jitter\"]:\n",
    "        config[\"color_jitter_brightness\"] = trial.suggest_float(\"color_jitter_brightness\", 0.1, 0.5)\n",
    "        config[\"color_jitter_contrast\"] = trial.suggest_float(\"color_jitter_contrast\", 0.1, 0.5)\n",
    "        config[\"color_jitter_saturation\"] = trial.suggest_float(\"color_jitter_saturation\", 0.1, 0.5)\n",
    "        config[\"color_jitter_hue\"] = trial.suggest_float(\"color_jitter_hue\", 0.1, 0.2)\n",
    "\n",
    "    config[\"enable_affine\"] = trial.suggest_categorical(\"enable_affine\", [True, False])\n",
    "    if config[\"enable_affine\"]:\n",
    "        config[\"enable_affine_scale\"] = trial.suggest_categorical(\"enable_affine_scale\", [True, False])\n",
    "        if config[\"enable_affine_scale\"]:\n",
    "            config[\"affine_scale_min\"] = trial.suggest_float(\"affine_scale_min\", 0.05, 0.2)\n",
    "            config[\"affine_scale_max\"] = trial.suggest_float(\"affine_scale_max\", config[\"affine_scale_min\"], 0.5)\n",
    "\n",
    "        config[\"enable_affine_rotate\"] = trial.suggest_categorical(\"enable_affine_rotate\", [True, False])\n",
    "        if config[\"enable_affine_rotate\"]:\n",
    "            config[\"affine_rotate_min\"] = trial.suggest_float(\"affine_rotate_min\", -20, -15)\n",
    "            config[\"affine_rotate_max\"] = trial.suggest_float(\"affine_rotate_max\", 15, 20)\n",
    "\n",
    "        config[\"enable_affine_shear\"] = trial.suggest_categorical(\"enable_affine_shear\", [True, False])\n",
    "        if config[\"enable_affine_shear\"]:\n",
    "            config[\"affine_shear_min\"] = trial.suggest_float(\"affine_shear_min\", -20, -15)\n",
    "            config[\"affine_shear_max\"] = trial.suggest_float(\"affine_shear_max\", 15, 20)\n",
    "\n",
    "    return train_model(config)\n"
   ],
   "id": "c451905f7e71bccb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tracker = EmissionsTracker(log_level=\"info\")\n",
    "tracker.start()\n",
    "\n",
    "num_random_models = 30\n",
    "random_results = []\n",
    "for i in range(num_random_models):\n",
    "    config = sample_trial_config()\n",
    "    val_map = train_model(config)\n",
    "    random_results.append({\"model\": i + 1, \"val_map\": val_map, \"config\": config})\n",
    "\n",
    "emissions = tracker.stop()\n",
    "print(f\"Estimated CO2 emissions: {emissions:.6f} kg\")"
   ],
   "id": "5e9a791e82917db3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"optuna_random_fusion\")\n",
    "study.optimize(objective, n_trials=30)  # adjust number of trials"
   ],
   "id": "c648e60fe54d5a91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
